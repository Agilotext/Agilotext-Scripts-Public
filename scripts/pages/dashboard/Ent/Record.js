document.addEventListener('DOMContentLoaded', function () {
  const DBG = !!window.AGILO_DEBUG;

  const MAX_RECORDING_MS = null;
  const MIN_BLOB_BYTES = 2048;

  const MIC_CONSTRAINTS_BASE = {
    echoCancellation: true,
    noiseSuppression: true,
    autoGainControl: false, // D√©sactiv√© car on a un AGC custom (√©vite double AGC / pompage)
    channelCount: 1,
    sampleRate: 48000
  };

  const MIX_PREGAIN_DB = 6.0; // Traitement fort pour transcription : gain global √©lev√©

  const MIC_BASE_GAIN = 1.8;  // Traitement fort : gain micro √©lev√© (+80%)
  const SYS_BASE_GAIN = 1.2;  // Traitement fort : gain audio syst√®me (+20%)

  const AGC_ENABLED = true;
  const AGC_TARGET = 0.35; // Traitement fort : cible RMS √©lev√©e (35%) pour signal constant
  const AGC_SMOOTH = 0.03;  // R√©actif pour traitement fort
  const AGC_MIN_GAIN = 0.60;  // Permet de baisser si trop fort
  const AGC_MAX_GAIN = 4.0;   // Traitement fort : amplification max √©lev√©e (400%)

  const MIC_COMP = {
    threshold: -30,   // Traitement fort : compresse t√¥t
    knee: 10,         // Transition nette
    ratio: 3.5,       // Traitement fort : compression agressive
    attack: 0.002,    // Tr√®s rapide
    release: 0.15     // Release court
  };

  const MIX_LIMITER = {
    threshold: -0.5,  // Traitement fort : proche de 0dB pour niveau constant
    knee: 0,
    ratio: 20,
    attack: 0.001,
    release: 0.08     // Rapide
  };

  /* --------- DOM --------- */
  const startButton = document.querySelector('.startrecording');
  const stopButton = document.getElementById('stopRecording');
  const pauseButton = document.getElementById('pauseRecording');
  const pauseButtonText = document.getElementById('pauseButtonText');
  const recordingAnimation = document.getElementById('Recording_animation');
  const recordingTimeDisplay = document.getElementById('recordingTime');
  const form = document.querySelector('form[ms-code-file-upload="form"]');
  const submitButton = document.getElementById('submit-button');
  const newButton = document.getElementById('newButton');
  const recordingDiv = document.getElementById('recordingDiv');
  const startSharingButton = document.getElementById('recording_sharing');
  const startAudioButton = document.getElementById('recording_audio');
  const errorMessage = document.getElementById('error-message_recording');
  const levelFill = document.getElementById('audioLevelFill');

  /* --------- √âtat --------- */
  let mediaRecorder;
  let audioChunks = [];
  let recordingInterval;
  let elapsedTimeInSeconds = 0;
  let autoStopTimeout;
  let warned5min = false, warned1min = false;

  let audioContext = null;
  let destination = null;
  let isSharingScreen = false;

  let mixBus = null;
  let mixPreGain = null;
  let mixLimiter = null;

  let meterAnalyser = null;
  let meterData = null;
  let meterRafId = null;
  let lastMeterLevel = 0;
  let clipActive = false;
  let clipStartTs = 0;

  // D√©tection de silence prolong√©
  let silenceStartTime = null;
  const SILENCE_THRESHOLD = 0.02; // RMS minimum pour consid√©rer comme "son" (2%)
  const SILENCE_WARNING_MS = 2 * 60 * 1000; // 2 minutes avant avertissement
  const SILENCE_AUTO_STOP_MS = 15 * 60 * 1000; // 15 minutes avant arr√™t automatique
  let silenceWarningShown = false;
  let silenceAutoStopWarned = false;
  let silenceStopTriggered = false; // Verrou pour √©viter les d√©clenchements multiples

  // Exposer les variables de silence sur window pour le debug
  window.AGILO_SILENCE_DEBUG = {
    getState: () => ({
      silenceStartTime,
      SILENCE_THRESHOLD,
      SILENCE_WARNING_MS,
      SILENCE_AUTO_STOP_MS,
      silenceWarningShown,
      silenceAutoStopWarned,
      lastMeterLevel,
      isRecording: mediaRecorder && mediaRecorder.state === 'recording',
      silenceDuration: silenceStartTime ? performance.now() - silenceStartTime : 0
    })
  };

  // Exposer les stats audio pour debug
  window.AGILO_AUDIO_DEBUG = {
    getStats: () => ({
      micGain: micGainNode?.gain?.value,
      agcEnabled: AGC_ENABLED,
      mimeType: mediaRecorder?.mimeType,
      audioContextState: audioContext?.state,
      chunks: audioChunks.length,
      backupSessionId: backupSessionId,
      suspensionDetected: suspensionDetected,
      totalSuspensionMs: totalSuspensionMs,
      wakeLockActive: !!wakeLockSentinel
    }),
    recoverBackup: null,  // Set dynamically by checkForRecovery
    clearBackup: null,    // Set dynamically by checkForRecovery
    backupInfo: null      // Set dynamically by checkForRecovery
  };

  let micSourceNode = null;
  let micHPF = null;
  let micDeEsser = null; // De-esser l√©ger pour r√©duire les sifflantes
  let micCompressor = null;
  let micGainNode = null;
  let micAgcAnalyser = null;
  let micAgcData = null;
  let agcRafId = null;

  let sysSourceNode = null;
  let sysGainNode = null;

  let currentMicStream = null;
  let currentScreenStream = null;
  let lastMicDeviceId = null;
  let screenVideoTrack = null; // Pour pouvoir retirer le listener si besoin
  let onScreenEnded = null; // Handler nomm√© pour pouvoir le retirer

  let alertedNoSystemAudio = false;
  let stopInProgress = false; // Flag pour √©viter les doubles clics "Stop"

  // [NEW] Wake Lock
  let wakeLockSentinel = null;

  // [NEW] Heartbeat / d√©tection veille
  let heartbeatInterval = null;
  let lastHeartbeatTs = 0;
  const HEARTBEAT_INTERVAL_MS = 2000;
  const HEARTBEAT_GAP_THRESHOLD_MS = 5000; // >5s = suspension probable

  // [NEW] Chunk watchdog
  let lastChunkTs = 0;
  let chunkWatchdogInterval = null;
  let activeTimeslice = 250;
  const CHUNK_WATCHDOG_MULTIPLIER = 3;

  // [NEW] IndexedDB backup
  const IDB_NAME = 'agilo_recording_backup';
  const IDB_VERSION = 1;
  const IDB_STORE = 'chunks';
  let backupSessionId = null;

  // [NEW] Suspension recovery
  let suspensionDetected = false;
  let totalSuspensionMs = 0;

  // [NEW] Tab title
  const originalDocTitle = document.title;

  const log = (...a) => { if (DBG) console.log('[rec]', ...a); };
  const warn = (...a) => { if (DBG) console.warn('[rec]', ...a); };
  const err = (...a) => { console.error('[rec]', ...a); };

  const dbToGain = (db) => Math.pow(10, db / 20);

  /* =========================
     D√âTECTION NAVIGATEUR / MOBILE
     ========================= */
  function isMobileDevice() {
    return /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
  }

  function isIOS() {
    return /iPhone|iPad|iPod/i.test(navigator.userAgent);
  }

  function isSafari() {
    return /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
  }

  function isFirefox() {
    return /Firefox/i.test(navigator.userAgent);
  }

  function isChromeLike() {
    return /Chrome|Edg|Brave/i.test(navigator.userAgent) && !/OPR|Opera/i.test(navigator.userAgent);
  }

  // V√©rifier si getDisplayMedia est disponible
  function supportsDisplayMedia() {
    return !!(navigator.mediaDevices && navigator.mediaDevices.getDisplayMedia);
  }

  // V√©rifier si MediaRecorder est disponible
  function supportsMediaRecorder() {
    return typeof MediaRecorder !== 'undefined' && typeof MediaRecorder.isTypeSupported === 'function';
  }

  // V√©rifier si Web Audio API est disponible
  function supportsWebAudio() {
    return !!(window.AudioContext || window.webkitAudioContext);
  }

  /* =========================
     FALLBACKS POUR MOBILE / NAVIGATEURS
     ========================= */
  function stopStreamTracks(s) {
    try { s && s.getTracks && s.getTracks().forEach(t => t.stop()); } catch { }
  }

  function formatDurationDigital(totalSeconds) {
    const h = Math.floor(totalSeconds / 3600);
    const m = Math.floor((totalSeconds % 3600) / 60);
    const s = totalSeconds % 60;
    const pad = n => n.toString().padStart(2, '0');
    return h > 0 ? `${pad(h)}:${pad(m)}:${pad(s)}` : `${pad(m)}:${pad(s)}`;
  }

  function toggleAnimation(on) {
    if (recordingAnimation) recordingAnimation.style.display = on ? 'block' : 'none';
    if (recordingDiv) recordingDiv.style.display = on ? 'block' : 'none';
  }

  function updateRecordingTime() {
    elapsedTimeInSeconds++;
    if (recordingTimeDisplay) recordingTimeDisplay.innerText = formatDurationDigital(elapsedTimeInSeconds);

    if (Number.isFinite(MAX_RECORDING_MS)) {
      const remaining = Math.floor((MAX_RECORDING_MS / 1000) - elapsedTimeInSeconds);
      if (!warned5min && remaining === 300) { warned5min = true; alert("Il reste 5 minutes d'enregistrement."); }
      if (!warned1min && remaining === 60) { warned1min = true; alert("Il reste 1 minute d'enregistrement."); }
    }
  }

  function simulateFileInput(fileInput, file) {
    if (!fileInput) return;
    // Fallback pour navigateurs anciens
    if (typeof DataTransfer !== 'undefined') {
      const dt = new DataTransfer();
      dt.items.add(file);
      fileInput.files = dt.files;
      fileInput.dispatchEvent(new Event('change', { bubbles: true }));
    } else {
      // Fallback pour navigateurs tr√®s anciens
      const reader = new FileReader();
      reader.onload = function (e) {
        fileInput.value = '';
        fileInput.dispatchEvent(new Event('change', { bubbles: true }));
      };
      reader.readAsDataURL(file);
    }
  }

  function downloadRecording(blob, filename) {
    const url = URL.createObjectURL(blob);
    const a = Object.assign(document.createElement('a'), { href: url, download: filename });
    a.style.display = 'none';
    document.body.appendChild(a);
    a.click();
    setTimeout(() => {
      URL.revokeObjectURL(url);
      a.remove();
    }, 100);
  }

  function showTabAudioHintOnce() {
    if (!isChromeLike() || isMobileDevice()) return;
    if (document.getElementById('tab-audio-hint')) return;

    const hint = document.createElement('div');
    hint.id = 'tab-audio-hint';
    hint.textContent = 'Partage un "Onglet Chrome" et coche "Partager l\'audio de l\'onglet" pour capter la voix de l\'autre.';
    Object.assign(hint.style, {
      position: 'fixed', bottom: '12px', left: '12px', background: '#111', color: '#fff',
      padding: '8px 12px', borderRadius: '6px', fontSize: '13px', opacity: .92, zIndex: 99999
    });
    document.body.appendChild(hint);
    setTimeout(() => hint.remove(), 8000);
  }

  /* =========================
     Gestion erreurs (comme ancien script)
     ========================= */

  /* ---------------- VU-m√®tre ---------------- */
  function startLevelMeter() {
    if (!audioContext || !levelFill || !meterAnalyser || !meterData) return;
    if (meterRafId) cancelAnimationFrame(meterRafId);
    lastMeterLevel = 0;
    clipActive = false; clipStartTs = 0;

    const loop = () => {
      if (!meterAnalyser || !meterData || !levelFill) return;

      try {
        meterAnalyser.getByteTimeDomainData(meterData);

        let sum = 0;
        for (let i = 0; i < meterData.length; i++) {
          const v = (meterData[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / meterData.length);

        // D√©tection de silence prolong√©
        checkSilence(rms);

        const BOOST = 4;
        const rawLevel = Math.min(1, rms * BOOST);

        const SMOOTH = 0.3;
        const level = SMOOTH * rawLevel + (1 - SMOOTH) * lastMeterLevel;
        lastMeterLevel = level;

        const pct = Math.round(level * 100);
        levelFill.style.width = pct + '%';
        levelFill.style.backgroundColor =
          level < 0.15 ? '#a82c33' : (level < 0.7 ? '#1c661a' : '#fd7e14');

        const now = performance.now();
        if (level > 0.95) {
          if (!clipActive) { clipActive = true; clipStartTs = now; }
          if (now - clipStartTs > 150) levelFill.style.outline = '2px solid rgba(255,0,0,.75)';
        } else {
          clipActive = false;
          levelFill.style.outline = '';
        }
      } catch (e) {
        warn('Erreur VU-m√®tre:', e);
      }

      meterRafId = requestAnimationFrame(loop);
    };

    loop();
  }

  function stopLevelMeter() {
    if (meterRafId) { cancelAnimationFrame(meterRafId); meterRafId = null; }
    if (levelFill) {
      levelFill.style.width = '0%';
      levelFill.style.backgroundColor = '#a82c33';
      levelFill.style.outline = '';
    }
    meterAnalyser = null;
    meterData = null;
    lastMeterLevel = 0;
    // R√©initialiser la d√©tection de silence
    silenceStartTime = null;
    silenceWarningShown = false;
    silenceAutoStopWarned = false;
  }

  /* ---------------- Forcer l'attention de l'utilisateur ---------------- */
  let titleBlinkInterval = null;
  const originalTitle = document.title;

  function forcePageFocus(message) {
    // Changer le titre de l'onglet pour attirer l'attention
    if (titleBlinkInterval) clearInterval(titleBlinkInterval);

    let blinkCount = 0;
    const maxBlinks = 20; // Clignoter pendant 10 secondes (20 * 500ms)

    titleBlinkInterval = setInterval(() => {
      if (blinkCount >= maxBlinks) {
        clearInterval(titleBlinkInterval);
        titleBlinkInterval = null;
        document.title = originalTitle;
        return;
      }
      document.title = blinkCount % 2 === 0 ? '‚ö†Ô∏è ATTENTION - ' + message : originalTitle;
      blinkCount++;
    }, 500);

    // Essayer de forcer le focus de la fen√™tre
    try {
      window.focus();
      if (document.hasFocus && !document.hasFocus()) {
        window.focus();
      }
    } catch (e) {
      warn('Impossible de forcer le focus:', e);
    }

    // Utiliser l'API Notification si disponible et autoris√©e
    if ('Notification' in window) {
      if (Notification.permission === 'granted') {
        try {
          new Notification('‚ö†Ô∏è Attention - Enregistrement', {
            body: message,
            icon: '/favicon.ico',
            tag: 'silence-warning',
            requireInteraction: true
          });
        } catch (e) {
          warn('Erreur Notification:', e);
        }
      } else if (Notification.permission === 'default') {
        // Demander la permission (mais seulement une fois)
        Notification.requestPermission().then(permission => {
          if (permission === 'granted') {
            try {
              new Notification('‚ö†Ô∏è Attention - Enregistrement', {
                body: message,
                icon: '/favicon.ico',
                tag: 'silence-warning',
                requireInteraction: true
              });
            } catch (e) {
              warn('Erreur Notification:', e);
            }
          }
        });
      }
    }
  }

  function stopTitleBlink() {
    if (titleBlinkInterval) {
      clearInterval(titleBlinkInterval);
      titleBlinkInterval = null;
      document.title = originalTitle;
    }
  }

  /* ================ [NEW] WAKE LOCK ================ */
  async function requestWakeLock() {
    if (!('wakeLock' in navigator)) { warn('Wake Lock API non support√©e'); return; }
    try {
      wakeLockSentinel = await navigator.wakeLock.request('screen');
      log('Wake Lock acquis');
      wakeLockSentinel.addEventListener('release', () => {
        log('Wake Lock rel√¢ch√©');
      });
    } catch (e) {
      warn('Wake Lock refus√©:', e);
    }
  }

  async function releaseWakeLock() {
    if (wakeLockSentinel) {
      try { await wakeLockSentinel.release(); } catch (e) { warn('Erreur release Wake Lock:', e); }
      wakeLockSentinel = null;
    }
  }

  /* ================ [NEW] HEARTBEAT / D√âTECTION VEILLE ================ */
  function startHeartbeat() {
    lastHeartbeatTs = Date.now();
    suspensionDetected = false;
    totalSuspensionMs = 0;
    if (heartbeatInterval) clearInterval(heartbeatInterval);

    heartbeatInterval = setInterval(() => {
      const now = Date.now();
      const gap = now - lastHeartbeatTs;

      if (gap > HEARTBEAT_GAP_THRESHOLD_MS) {
        warn('‚ö†Ô∏è Suspension d√©tect√©e: gap de', gap, 'ms (' + Math.round(gap / 1000) + 's)');
        suspensionDetected = true;
        totalSuspensionMs += gap - HEARTBEAT_INTERVAL_MS;
        handleSuspendRecovery(gap);
      }

      lastHeartbeatTs = now;
    }, HEARTBEAT_INTERVAL_MS);
  }

  function stopHeartbeat() {
    if (heartbeatInterval) { clearInterval(heartbeatInterval); heartbeatInterval = null; }
  }

  function handleSuspendRecovery(gapMs) {
    const gapSec = Math.round(gapMs / 1000);
    const gapMin = Math.floor(gapSec / 60);
    const gapSecRem = gapSec % 60;

    // Tenter de reprendre AudioContext
    if (audioContext && audioContext.state === 'suspended') {
      audioContext.resume().then(() => {
        log('AudioContext repris apr√®s suspension');
      }).catch(e => {
        warn('√âchec resume AudioContext apr√®s suspension:', e);
      });
    }

    // Tenter de flush les donn√©es pendantes
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      try { mediaRecorder.requestData(); } catch (e) {
        warn('Erreur requestData apr√®s suspension:', e);
      }
    }

    // Si MediaRecorder est devenu inactive = l'enregistrement est mort
    if (mediaRecorder && mediaRecorder.state === 'inactive') {
      err('MediaRecorder devenu inactive apr√®s suspension !');
      forcePageFocus('Enregistrement interrompu par la veille');
      alert('‚ö†Ô∏è L\'enregistrement a √©t√© interrompu par la mise en veille de votre ordinateur.\n\nLes donn√©es enregistr√©es avant la mise en veille ont √©t√© sauvegard√©es localement.\n\nDur√©e de la coupure : ' + (gapMin > 0 ? gapMin + ' min ' : '') + gapSecRem + ' s');
      return;
    }

    // R√©-acqu√©rir le Wake Lock (il est perdu pendant la veille)
    requestWakeLock();

    // Avertir l'utilisateur si coupure significative (> 30s)
    const timeStr = gapMin > 0 ? gapMin + ' min ' + gapSecRem + ' s' : gapSec + ' s';
    if (gapMs > 30000) {
      forcePageFocus('Veille d√©tect√©e - ' + timeStr);
      alert('‚ö†Ô∏è Votre ordinateur s\'est mis en veille pendant ' + timeStr + '.\n\nL\'enregistrement a pu √™tre affect√©. Les donn√©es avant la coupure sont sauvegard√©es.\n\nüí° Pour √©viter ce probl√®me :\n- Gardez votre ordinateur branch√©\n- Ne fermez pas l\'√©cran\n- V√©rifiez les r√©glages d\'√©conomie d\'√©nergie');
    }
  }

  /* ================ [NEW] CHUNK WATCHDOG ================ */
  function startChunkWatchdog(timesliceMs) {
    lastChunkTs = Date.now();
    if (chunkWatchdogInterval) clearInterval(chunkWatchdogInterval);

    const threshold = timesliceMs * CHUNK_WATCHDOG_MULTIPLIER;

    chunkWatchdogInterval = setInterval(() => {
      if (!mediaRecorder || mediaRecorder.state !== 'recording') return;

      const elapsed = Date.now() - lastChunkTs;
      if (elapsed > threshold) {
        warn('Chunk watchdog: aucun chunk depuis', elapsed, 'ms (seuil:', threshold, 'ms)');
        try {
          mediaRecorder.requestData();
          log('requestData() forc√© par watchdog');
        } catch (e) {
          warn('Erreur requestData watchdog:', e);
        }
      }
    }, timesliceMs * 2);
  }

  function stopChunkWatchdog() {
    if (chunkWatchdogInterval) { clearInterval(chunkWatchdogInterval); chunkWatchdogInterval = null; }
  }

  /* ================ [NEW] INDEXEDDB BACKUP ================ */
  function openBackupDB() {
    return new Promise((resolve, reject) => {
      try {
        const req = indexedDB.open(IDB_NAME, IDB_VERSION);
        req.onupgradeneeded = (e) => {
          const db = e.target.result;
          if (!db.objectStoreNames.contains(IDB_STORE)) {
            db.createObjectStore(IDB_STORE, { keyPath: 'id', autoIncrement: true });
          }
        };
        req.onsuccess = () => resolve(req.result);
        req.onerror = () => { warn('IndexedDB open error:', req.error); reject(req.error); };
      } catch (e) {
        warn('IndexedDB non disponible:', e);
        reject(e);
      }
    });
  }

  async function saveChunkToBackup(blob) {
    if (!backupSessionId) return;
    try {
      const db = await openBackupDB();
      const tx = db.transaction(IDB_STORE, 'readwrite');
      tx.objectStore(IDB_STORE).add({
        sessionId: backupSessionId,
        blob: blob,
        timestamp: Date.now()
      });
      await new Promise((resolve, reject) => {
        tx.oncomplete = resolve;
        tx.onerror = () => reject(tx.error);
      });
      db.close();
    } catch (e) {
      warn('Erreur sauvegarde chunk IndexedDB:', e);
    }
  }

  async function startBackupSession() {
    backupSessionId = 'rec_' + Date.now() + '_' + Math.random().toString(36).substr(2, 6);
    try {
      const db = await openBackupDB();
      const tx = db.transaction(IDB_STORE, 'readwrite');
      tx.objectStore(IDB_STORE).add({
        sessionId: backupSessionId,
        type: 'session_start',
        startTime: Date.now(),
        blob: null
      });
      await new Promise((resolve, reject) => {
        tx.oncomplete = resolve;
        tx.onerror = () => reject(tx.error);
      });
      db.close();
      log('Backup session d√©marr√©e:', backupSessionId);
    } catch (e) {
      warn('Erreur d√©marrage backup session:', e);
      backupSessionId = null;
    }
  }

  async function clearBackupSession() {
    if (!backupSessionId) return;
    try {
      const db = await openBackupDB();
      const tx = db.transaction(IDB_STORE, 'readwrite');
      const store = tx.objectStore(IDB_STORE);
      const req = store.getAll();
      req.onsuccess = () => {
        const records = req.result;
        records.forEach(r => {
          if (r.sessionId === backupSessionId) store.delete(r.id);
        });
      };
      await new Promise((resolve, reject) => {
        tx.oncomplete = resolve;
        tx.onerror = () => reject(tx.error);
      });
      db.close();
      log('Backup session nettoy√©e:', backupSessionId);
      backupSessionId = null;
    } catch (e) {
      warn('Erreur nettoyage backup session:', e);
      backupSessionId = null;
    }
  }

  async function recoverBackupSession() {
    try {
      const db = await openBackupDB();
      const tx = db.transaction(IDB_STORE, 'readonly');
      const req = tx.objectStore(IDB_STORE).getAll();

      return new Promise((resolve, reject) => {
        req.onsuccess = () => {
          const records = req.result;
          db.close();
          if (!records || records.length === 0) { resolve(null); return; }

          // Grouper par sessionId
          const sessions = {};
          records.forEach(r => {
            if (!sessions[r.sessionId]) sessions[r.sessionId] = [];
            sessions[r.sessionId].push(r);
          });

          // Trouver la session la plus r√©cente avec des chunks
          let bestSession = null;
          let bestTime = 0;
          for (const sid in sessions) {
            const chunks = sessions[sid].filter(r => r.blob && r.blob.size > 0);
            const meta = sessions[sid].find(r => r.type === 'session_start');
            if (chunks.length > 0 && meta && meta.startTime > bestTime) {
              bestSession = { sessionId: sid, chunks, meta, allRecords: sessions[sid] };
              bestTime = meta.startTime;
            }
          }
          resolve(bestSession);
        };
        req.onerror = () => { db.close(); reject(req.error); };
      });
    } catch (e) {
      warn('Erreur lecture backup:', e);
      return null;
    }
  }

  async function exportBackupAsBlob(session) {
    if (!session || !session.chunks || session.chunks.length === 0) return null;
    const sorted = session.chunks.sort((a, b) => a.timestamp - b.timestamp);
    const blobs = sorted.map(c => c.blob);
    return new Blob(blobs, { type: blobs[0].type || 'audio/webm' });
  }

  async function clearAllBackups() {
    try {
      const db = await openBackupDB();
      const tx = db.transaction(IDB_STORE, 'readwrite');
      tx.objectStore(IDB_STORE).clear();
      await new Promise((resolve, reject) => {
        tx.oncomplete = resolve;
        tx.onerror = () => reject(tx.error);
      });
      db.close();
      log('Tous les backups nettoy√©s');
    } catch (e) {
      warn('Erreur nettoyage backups:', e);
    }
  }

  /* ================ [NEW] RECOVERY CHECK ================ */
  async function checkForRecovery() {
    try {
      const session = await recoverBackupSession();
      if (!session) return;

      const chunkCount = session.chunks.length;
      const totalSize = session.chunks.reduce((acc, c) => acc + (c.blob ? c.blob.size : 0), 0);
      const startTime = new Date(session.meta.startTime);
      const sizeMB = (totalSize / (1024 * 1024)).toFixed(1);

      log('Session de recovery d√©tect√©e:', chunkCount, 'chunks,', sizeMB, 'MB');

      // Exposer les helpers de recovery
      window.AGILO_AUDIO_DEBUG.recoverBackup = async () => {
        const blob = await exportBackupAsBlob(session);
        if (!blob) { console.warn('Aucun blob √† r√©cup√©rer'); return null; }
        downloadRecording(blob, 'Agilotext_RECOVERY_' + startTime.toISOString().slice(0, 10) + '.webm');
        return blob;
      };
      window.AGILO_AUDIO_DEBUG.clearBackup = () => clearAllBackups();
      window.AGILO_AUDIO_DEBUG.backupInfo = { sessionId: session.sessionId, chunks: chunkCount, sizeMB, startTime: startTime.toISOString() };

      // Afficher la banni√®re de recovery si assez de donn√©es
      if (chunkCount >= 2 && totalSize > MIN_BLOB_BYTES) {
        const recDiv = document.createElement('div');
        recDiv.id = 'agilo-recovery-banner';
        Object.assign(recDiv.style, {
          position: 'fixed', top: '0', left: '0', right: '0',
          background: 'linear-gradient(135deg, #ff6b00, #e65100)',
          color: '#fff', padding: '12px 16px', zIndex: '999999',
          fontSize: '14px', fontFamily: 'system-ui, sans-serif',
          display: 'flex', alignItems: 'center', justifyContent: 'space-between',
          boxShadow: '0 2px 8px rgba(0,0,0,.3)'
        });
        recDiv.innerHTML =
          '<span>\u26a0\ufe0f Un enregistrement pr\u00e9c\u00e9dent a \u00e9t\u00e9 retrouv\u00e9 (' + sizeMB + ' MB, ' + chunkCount + ' fragments). </span>' +
          '<span>' +
          '<button id="agilo-recovery-download" style="background:#fff;color:#e65100;border:none;padding:6px 14px;border-radius:4px;cursor:pointer;font-weight:bold;margin-right:8px;">\ud83d\udce5 T\u00e9l\u00e9charger</button>' +
          '<button id="agilo-recovery-dismiss" style="background:transparent;color:#fff;border:1px solid #fff;padding:6px 14px;border-radius:4px;cursor:pointer;">Ignorer</button>' +
          '</span>';
        document.body.appendChild(recDiv);

        document.getElementById('agilo-recovery-download').onclick = async () => {
          const blob = await exportBackupAsBlob(session);
          if (blob) downloadRecording(blob, 'Agilotext_RECOVERY_' + startTime.toISOString().slice(0, 10) + '.webm');
          recDiv.remove();
          await clearAllBackups();
        };
        document.getElementById('agilo-recovery-dismiss').onclick = async () => {
          recDiv.remove();
          await clearAllBackups();
        };
      }
    } catch (e) {
      warn('Erreur checkForRecovery:', e);
    }
  }

  /* ---------------- D√©tection de silence prolong√© ---------------- */
  function checkSilence(rms) {
    // Verrou : ne pas d√©clencher plusieurs fois l'arr√™t
    if (silenceStopTriggered) return;

    // Ne pas d√©tecter le silence si l'enregistrement n'est pas en cours
    if (!mediaRecorder || mediaRecorder.state !== 'recording') {
      // R√©initialiser si on n'est plus en enregistrement
      if (silenceStartTime !== null) {
        silenceStartTime = null;
        silenceWarningShown = false;
        silenceAutoStopWarned = false;
      }
      return;
    }

    if (rms < SILENCE_THRESHOLD) {
      // Silence d√©tect√©
      if (silenceStartTime === null) {
        silenceStartTime = performance.now();
      } else {
        const silenceDuration = performance.now() - silenceStartTime;

        // Avertissement apr√®s 2 minutes de silence
        if (silenceDuration > SILENCE_WARNING_MS && !silenceWarningShown) {
          silenceWarningShown = true;
          const minutes = Math.floor(silenceDuration / 60000);
          const message = `Aucun son d√©tect√© depuis ${minutes} minute(s).\n\nSi le silence continue pendant 15 minutes au total, l'enregistrement sera automatiquement arr√™t√© pour √©viter un fichier vide.`;

          // Forcer l'attention
          forcePageFocus('Silence d√©tect√© - V√©rifiez votre micro');

          alert(`‚ö†Ô∏è Attention : ${message}`);
        }

        // Avertissement avant arr√™t automatique (apr√®s 4 minutes)
        if (silenceDuration > (SILENCE_AUTO_STOP_MS - 60000) && !silenceAutoStopWarned) {
          silenceAutoStopWarned = true;
          const message = `Silence prolong√© d√©tect√©.\n\nL'enregistrement sera arr√™t√© automatiquement dans 1 minute si aucun son n'est d√©tect√©.`;

          // Forcer l'attention
          forcePageFocus('Arr√™t imminent - V√©rifiez votre micro');

          alert(`‚ö†Ô∏è Attention : ${message}`);
        }

        // Arr√™t automatique apr√®s 15 minutes de silence
        if (silenceDuration > SILENCE_AUTO_STOP_MS && !silenceStopTriggered) {
          // Verrou : √©viter les d√©clenchements multiples
          silenceStopTriggered = true;

          warn('Arr√™t automatique apr√®s 15 minutes de silence');

          // Forcer l'attention avant l'arr√™t
          forcePageFocus('Enregistrement arr√™t√© automatiquement');

          alert('‚èπÔ∏è Enregistrement arr√™t√© automatiquement : aucun son d√©tect√© pendant 15 minutes.\n\nL\'enregistrement a √©t√© interrompu pour √©viter un fichier vide.\n\nLe fichier sera sauvegard√© et envoy√© automatiquement.');

          // Utiliser Promise pour √©viter les races
          Promise.resolve()
            .then(() => {
              if (mediaRecorder && mediaRecorder.state === 'recording') {
                try { mediaRecorder.requestData(); } catch (e) {
                  warn('Erreur requestData avant arr√™t:', e);
                }
              }
            })
            .then(() => new Promise(r => setTimeout(r, 100)))
            .then(() => stopRecordingAndSubmitForm());

          return;
        }
      }
    } else {
      // Son d√©tect√©, r√©initialiser le compteur
      if (silenceStartTime !== null) {
        silenceStartTime = null;
        silenceWarningShown = false;
        silenceAutoStopWarned = false;
        // Arr√™ter le clignotement du titre si actif
        stopTitleBlink();
      }
    }
  }

  /* ---------------- AGC micro ---------------- */
  function startMicAutoGain() {
    if (!AGC_ENABLED) return;
    if (!micAgcAnalyser || !micAgcData || !micGainNode) return;
    if (agcRafId) cancelAnimationFrame(agcRafId);

    const loop = () => {
      if (!micAgcAnalyser || !micAgcData || !micGainNode) return;

      try {
        micAgcAnalyser.getByteTimeDomainData(micAgcData);

        let sum = 0;
        for (let i = 0; i < micAgcData.length; i++) {
          const v = (micAgcData[i] - 128) / 128;
          sum += v * v;
        }
        const rms = Math.sqrt(sum / micAgcData.length);

        const g = micGainNode.gain.value;
        if (rms > 0.001) {
          const desired = Math.min(AGC_MAX_GAIN, Math.max(AGC_MIN_GAIN, MIC_BASE_GAIN * (AGC_TARGET / rms)));
          micGainNode.gain.value = g + (desired - g) * AGC_SMOOTH;
        }
      } catch (e) {
        warn('Erreur AGC:', e);
      }

      agcRafId = requestAnimationFrame(loop);
    };

    loop();
  }

  function stopMicAutoGain() {
    if (agcRafId) { cancelAnimationFrame(agcRafId); agcRafId = null; }
  }

  /* ---------------- Audio graph ---------------- */
  function setupAudioContext() {
    if (!supportsWebAudio()) {
      err('Web Audio API non support√©');
      return;
    }

    try {
      audioContext = new (window.AudioContext || window.webkitAudioContext)();
    } catch (e) {
      err('Impossible de cr√©er AudioContext:', e);
      return;
    }

    try {
      destination = audioContext.createMediaStreamDestination();
    } catch (e) {
      err('Impossible de cr√©er MediaStreamDestination:', e);
      return;
    }

    mixBus = audioContext.createGain();
    mixBus.gain.value = 1.0;

    mixPreGain = audioContext.createGain();
    mixPreGain.gain.value = dbToGain(MIX_PREGAIN_DB);

    mixLimiter = audioContext.createDynamicsCompressor();
    mixLimiter.threshold.value = MIX_LIMITER.threshold;
    mixLimiter.knee.value = MIX_LIMITER.knee;
    mixLimiter.ratio.value = MIX_LIMITER.ratio;
    mixLimiter.attack.value = MIX_LIMITER.attack;
    mixLimiter.release.value = MIX_LIMITER.release;

    mixBus.connect(mixPreGain);
    mixPreGain.connect(mixLimiter);
    mixLimiter.connect(destination);

    if (levelFill) {
      meterAnalyser = audioContext.createAnalyser();
      meterAnalyser.fftSize = 512;
      meterData = new Uint8Array(meterAnalyser.fftSize);
      mixLimiter.connect(meterAnalyser);
    }

    micHPF = audioContext.createBiquadFilter();
    micHPF.type = 'highpass';
    micHPF.frequency.value = 80;

    // De-esser l√©ger pour r√©duire les sifflantes (utile pour la transcription)
    micDeEsser = audioContext.createBiquadFilter();
    micDeEsser.type = 'peaking';
    micDeEsser.frequency.value = 6000;  // Fr√©quence des sifflantes
    micDeEsser.Q.value = 2;
    micDeEsser.gain.value = -3;         // -3dB

    micCompressor = audioContext.createDynamicsCompressor();
    micCompressor.threshold.value = MIC_COMP.threshold;
    micCompressor.knee.value = MIC_COMP.knee;
    micCompressor.ratio.value = MIC_COMP.ratio;
    micCompressor.attack.value = MIC_COMP.attack;
    micCompressor.release.value = MIC_COMP.release;

    micGainNode = audioContext.createGain();
    micGainNode.gain.value = MIC_BASE_GAIN;

    micAgcAnalyser = audioContext.createAnalyser();
    micAgcAnalyser.fftSize = 512;
    micAgcData = new Uint8Array(micAgcAnalyser.fftSize);

    sysGainNode = audioContext.createGain();
    sysGainNode.gain.value = SYS_BASE_GAIN;

    // Note: AudioContext.resume() doit √™tre appel√© dans un handler utilisateur (initiateRecording)
    // On ne le fait pas ici car setupAudioContext() peut √™tre appel√© sans interaction utilisateur
  }

  function teardownAudioGraph() {
    stopMicAutoGain();
    stopLevelMeter();

    try { micSourceNode && micSourceNode.disconnect(); } catch { }
    try { sysSourceNode && sysSourceNode.disconnect(); } catch { }
    try { micHPF && micHPF.disconnect(); } catch { }
    try { micDeEsser && micDeEsser.disconnect(); } catch { }
    try { micCompressor && micCompressor.disconnect(); } catch { }
    try { micGainNode && micGainNode.disconnect(); } catch { }
    try { sysGainNode && sysGainNode.disconnect(); } catch { }
    try { mixBus && mixBus.disconnect(); } catch { }
    try { mixPreGain && mixPreGain.disconnect(); } catch { }
    try { mixLimiter && mixLimiter.disconnect(); } catch { }
    try { meterAnalyser && meterAnalyser.disconnect(); } catch { }
    try { micAgcAnalyser && micAgcAnalyser.disconnect(); } catch { }

    micSourceNode = null;
    sysSourceNode = null;
    micHPF = null;
    micDeEsser = null;
    micCompressor = null;
    micGainNode = null;
    sysGainNode = null;
    mixBus = null;
    mixPreGain = null;
    mixLimiter = null;
    meterAnalyser = null;
    micAgcAnalyser = null;
    micAgcData = null;

    try { if (audioContext && audioContext.state !== 'closed') audioContext.close(); } catch { }
    audioContext = null;
    destination = null;
  }

  /* ---------------- Start buttons ---------------- */
  if (startAudioButton) {
    startAudioButton.onclick = function () {
      // Audio seul : toujours possible via initiateRecording(false)
      // Pas de restriction navigateur sauf si getUserMedia n'est pas support√© (d√©j√† v√©rifi√© au d√©but)
      initiateRecording(false);
    };
  }

  if (startSharingButton) {
    startSharingButton.onclick = function () {
      // 1. Mobile : pas de partage d'√©cran possible -> fallback micro
      if (isMobileDevice()) {
        if (confirm('Le partage d\'√©cran n\'est pas disponible sur mobile.\nVoulez-vous enregistrer uniquement le micro ?')) {
          initiateRecording(false);
        }
        return;
      }

      // 2. Firefox : supporte getDisplayMedia mais sans audio syst√®me -> warning + enregistrement
      if (isFirefox()) {
        if (confirm('‚ö†Ô∏è Firefox ne capture PAS l\'audio du syst√®me (r√©unions en ligne).\n\nL\'enregistrement ne contiendra QUE votre voix.\n\nPour enregistrer une r√©union, utilisez Chrome, Edge ou Safari (r√©cent).\n\nContinuer en mode micro seul ?')) {
          // On lance en mode partage d'√©cran (true) pour qu'il tente quand m√™me,
          // mais le script g√©rera le fallback ou l'absence de track audio.
          // OU MIEUX : On lance direct le mode micro pour √©viter la confusion
          initiateRecording(false);
        }
        return;
      }

      // 3. Autres navigateurs (Chrome, Edge, Safari, Opera...)
      // Si `getDisplayMedia` est support√©, on lance le flux partage d'√©cran
      if (supportsDisplayMedia()) {
        initiateRecording(true);
      } else {
        // Fallback si vraiment pas support√© (ex: vieux Safari < 13)
        if (confirm('Votre navigateur ne supporte pas le partage d\'√©cran.\nVoulez-vous enregistrer uniquement le micro ?')) {
          initiateRecording(false);
        }
      }
    };
  }

  function effectiveMicConstraints() {
    const c = { audio: {} };

    // Sur mobile/iOS, on simplifie les contraintes
    if (isMobileDevice() || isIOS()) {
      c.audio = { echoCancellation: true };
    } else {
      Object.assign(c.audio, MIC_CONSTRAINTS_BASE);
    }

    if (lastMicDeviceId) {
      c.audio.deviceId = { exact: lastMicDeviceId };
    }

    return c;
  }

  async function getMicStreamWithFallback() {
    try {
      return await navigator.mediaDevices.getUserMedia(effectiveMicConstraints());
    } catch (e1) {
      warn('getUserMedia exact device failed -> fallback audio:true', e1);
      try {
        return await navigator.mediaDevices.getUserMedia({ audio: true });
      } catch (e2) {
        warn('getUserMedia audio:true failed -> fallback minimal', e2);
        // Dernier recours : contraintes minimales
        return await navigator.mediaDevices.getUserMedia({ audio: {} });
      }
    }
  }

  function attachMicTrackListeners(stream) {
    const track = stream && stream.getAudioTracks && stream.getAudioTracks()[0];
    if (!track) return;

    try {
      const s = track.getSettings && track.getSettings();
      if (s && s.deviceId) lastMicDeviceId = s.deviceId;
    } catch (e) {
      warn('Impossible de r√©cup√©rer deviceId:', e);
    }

    track.addEventListener('ended', () => {
      warn('Piste micro ended -> tentative de recovery');
      if (mediaRecorder && mediaRecorder.state === 'recording') restartMic();
    });

    track.addEventListener('mute', () => warn('Piste micro mute'));
    track.addEventListener('unmute', () => warn('Piste micro unmute'));
  }

  async function initiateRecording(shareScreen) {
    if (mediaRecorder && mediaRecorder.state === 'recording') return;

    // AJOUT : R√©activer AudioContext dans le contexte utilisateur (iOS)
    if (audioContext && audioContext.state === 'suspended') {
      try {
        await audioContext.resume();
      } catch (e) {
        warn('AudioContext.resume() dans initiateRecording:', e);
      }
    }

    // V√©rifications de compatibilit√©
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      alert('Votre navigateur ne supporte pas l\'enregistrement audio. Veuillez utiliser un navigateur r√©cent (Chrome, Firefox, Safari, Edge).');
      return;
    }

    if (!supportsMediaRecorder()) {
      alert('Votre navigateur ne supporte pas MediaRecorder. Veuillez utiliser un navigateur r√©cent.');
      return;
    }

    // Pas besoin d'initialiser quoi que ce soit, on utilise juste errorMessage existant

    setupAudioContext();

    // V√©rifier que setupAudioContext() a r√©ussi
    if (!destination || !destination.stream) {
      alert("Votre navigateur ne supporte pas le mixage audio (WebAudio). Essayez Chrome/Edge.");
      stopStreamTracks(currentMicStream);
      currentMicStream = null;
      stopStreamTracks(currentScreenStream);
      currentScreenStream = null;
      teardownAudioGraph();
      return;
    }

    // V√©rification des permissions (avec fallback pour navigateurs sans Permissions API)
    try {
      if (navigator.permissions && navigator.permissions.query) {
        try {
          const res = await navigator.permissions.query({ name: 'microphone' });
          if (res.state !== 'granted') {
            // On continue quand m√™me, l'erreur sera g√©r√©e par getUserMedia
          }
        } catch (e) {
          // Permissions API non support√©e ou erreur, on continue
          warn('Permissions API non disponible:', e);
        }
      }
    } catch { }

    // Micro
    try {
      currentMicStream = await getMicStreamWithFallback();
      attachMicTrackListeners(currentMicStream);
    } catch (e) {
      err('getUserMedia audio:', e);
      stopButton && (stopButton.style.display = 'none');
      pauseButton && (pauseButton.style.display = 'none');
      if (errorMessage) errorMessage.style.display = 'block';

      let errorMsg = 'Erreur lors de l\'acc√®s au microphone: ';
      if (e.name === 'NotAllowedError') {
        errorMsg += 'Permission refus√©e. Veuillez autoriser l\'acc√®s au microphone dans les param√®tres de votre navigateur.';
      } else if (e.name === 'NotFoundError') {
        errorMsg += 'Aucun microphone trouv√©. V√©rifiez que votre microphone est connect√©.';
      } else {
        errorMsg += e.message || e;
      }

      alert(errorMsg);
      teardownAudioGraph();
      return;
    }

    // Onglet/√©cran (seulement si demand√© ET disponible)
    if (shareScreen && !isSharingScreen && supportsDisplayMedia()) {
      isSharingScreen = true;
      try {
        currentScreenStream = await navigator.mediaDevices.getDisplayMedia({ video: true, audio: true });
        // Stocker la piste vid√©o mais NE PAS attacher le listener tout de suite
        // (on l'attachera seulement si on garde vraiment le stream apr√®s le check hasSystemAudio)
        screenVideoTrack = currentScreenStream.getVideoTracks && currentScreenStream.getVideoTracks()[0] || null;

        currentScreenStream.addEventListener?.('addtrack', (e) => {
          if (e.track && e.track.kind === 'audio') {
            warn('Nouvelle piste audio √©cran ajout√©e -> rebind');
            bindSystemToGraph(currentScreenStream);
          }
        });

      } catch (e) {
        err('getDisplayMedia:', e);
        // Afficher l'erreur comme dans l'ancien script : div error + popup
        if (errorMessage) errorMessage.style.display = 'block';
        if (stopButton) stopButton.style.display = 'none';
        if (pauseButton) pauseButton.style.display = 'none';

        // Diff√©rencier les types d'erreurs
        let errorMsg;
        if (e.name === 'NotAllowedError') {
          errorMsg = 'Permission de partage d\'√©cran refus√©e.\n\nPour capter l\'audio d\'un onglet, partage un "Onglet Chrome" et coche "Partager l\'audio".';
        } else if (e.name === 'NotFoundError') {
          errorMsg = 'Aucune source de partage trouv√©e.';
        } else if (e.name === 'AbortError') {
          errorMsg = 'Partage d\'√©cran annul√©.';
        } else {
          errorMsg = 'Erreur de partage d\'√©cran : ' + (e.message || e.name || 'Erreur inconnue');
        }
        alert(errorMsg);

        isSharingScreen = false;
        currentScreenStream = null;
        screenVideoTrack = null;
        // Nettoyer les ressources
        stopStreamTracks(currentMicStream);
        currentMicStream = null;
        teardownAudioGraph();
        return; // NE PAS d√©marrer l'enregistrement
      }
    } else if (shareScreen && !supportsDisplayMedia()) {
      // getDisplayMedia non disponible, on continue avec micro seul
      warn('getDisplayMedia non disponible, enregistrement micro seul');
    }

    // V√©rifier l'audio syst√®me AVANT de d√©marrer l'enregistrement
    if (shareScreen && currentScreenStream) {
      const hasSystemAudio = !!(currentScreenStream.getAudioTracks && currentScreenStream.getAudioTracks().length > 0);
      if (!hasSystemAudio) {
        // Firefox ne supporte pas l'audio syst√®me via getDisplayMedia
        // On fait un fallback : continuer en micro seul avec un message explicite
        if (isFirefox()) {
          warn('Firefox : pas d\'audio syst√®me d√©tect√©, enregistrement micro seul');
          alert('‚ö†Ô∏è Firefox ne supporte pas la capture de l\'audio syst√®me/onglet.\n\nL\'enregistrement continuera avec votre micro uniquement.\n\nPour capter la voix de l\'autre personne, utilisez Chrome ou Edge.');
          // On continue avec micro seul (pas de currentScreenStream)
          // IMPORTANT : lib√©rer la capture √©cran (on n'a pas encore attach√© le listener ended, donc c'est safe)
          stopStreamTracks(currentScreenStream);
          currentScreenStream = null;
          screenVideoTrack = null;
          isSharingScreen = false;
        } else {
          // Sur Chrome/Edge : bloquer si pas d'audio syst√®me (c'est possible, donc on doit l'exiger)
          err('Pas d\'audio syst√®me d√©tect√©, enregistrement annul√©');
          if (errorMessage) errorMessage.style.display = 'block';
          if (stopButton) stopButton.style.display = 'none';
          if (pauseButton) pauseButton.style.display = 'none';
          alert('Astuce : s√©lectionnez "Onglet Chrome" et cochez "Partager l\'audio de l\'onglet" pour capter la voix de l\'autre.');
          // Afficher l'aide pour Chrome/Edge
          showTabAudioHintOnce();
          // Nettoyer les ressources (pas de listener attach√© donc pas de probl√®me)
          stopStreamTracks(currentMicStream);
          stopStreamTracks(currentScreenStream);
          currentMicStream = null;
          currentScreenStream = null;
          screenVideoTrack = null;
          teardownAudioGraph();
          return; // NE PAS d√©marrer l'enregistrement
        }
      } else {
        // BUG FIX #1 : On garde le stream, donc on peut maintenant attacher le listener ended
        // Utiliser une fonction nomm√©e pour pouvoir la retirer si besoin
        if (screenVideoTrack) {
          onScreenEnded = () => stopRecordingAndSubmitForm();
          screenVideoTrack.addEventListener('ended', onScreenEnded);
        }
      }
    }

    bindMicToGraph(currentMicStream);
    if (currentScreenStream) bindSystemToGraph(currentScreenStream);

    if (meterAnalyser && meterData) startLevelMeter();
    startMicAutoGain();

    startRecording(destination.stream);
  }

  function bindMicToGraph(micStream) {
    if (!audioContext || !mixBus || !micHPF || !micDeEsser || !micCompressor || !micGainNode || !micAgcAnalyser) return;

    try { micSourceNode && micSourceNode.disconnect(); } catch { }
    micSourceNode = null;

    try {
      micSourceNode = audioContext.createMediaStreamSource(micStream);

      micSourceNode.connect(micHPF);
      micHPF.connect(micDeEsser);
      micDeEsser.connect(micCompressor);

      micCompressor.connect(micAgcAnalyser);
      micCompressor.connect(micGainNode);
      micGainNode.connect(mixBus);
    } catch (e) {
      err('Erreur bindMicToGraph:', e);
    }
  }

  function bindSystemToGraph(screenStream) {
    if (!audioContext || !mixBus || !sysGainNode) return;

    try { sysSourceNode && sysSourceNode.disconnect(); } catch { }
    sysSourceNode = null;

    const hasSystemAudio = !!(screenStream.getAudioTracks && screenStream.getAudioTracks().length > 0);
    if (!hasSystemAudio) {
      // Cette fonction ne devrait pas √™tre appel√©e si pas d'audio syst√®me
      // car c'est v√©rifi√© dans initiateRecording avant
      warn('bindSystemToGraph appel√© sans audio syst√®me');
      return;
    }

    alertedNoSystemAudio = false;

    try {
      sysSourceNode = audioContext.createMediaStreamSource(screenStream);
      sysSourceNode.connect(sysGainNode);
      sysGainNode.connect(mixBus);
    } catch (e) {
      err('Erreur bindSystemToGraph:', e);
    }
  }

  async function restartMic() {
    try {
      const newMic = await getMicStreamWithFallback();
      stopStreamTracks(currentMicStream);
      currentMicStream = newMic;
      attachMicTrackListeners(currentMicStream);
      bindMicToGraph(currentMicStream);
      log('Micro r√©tabli.');
    } catch (e) {
      err('√âchec de r√©acquisition du micro:', e);
      alert("Le micro a √©t√© perdu (casque d√©connect√©). Merci de re-s√©lectionner un micro puis relancer l'enregistrement si besoin.");
    }
  }

  function getSupportedMimeType() {
    // Ordre de pr√©f√©rence selon les navigateurs
    const types = [
      'audio/webm; codecs=opus',  // Chrome, Edge, Firefox
      'audio/webm',               // Chrome, Edge (fallback)
      'audio/ogg; codecs=opus',   // Firefox
      'audio/mp4',                // Safari (limit√©)
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        return type;
      }
    }

    // Fallback : essayer sans sp√©cifier de codec
    return 'audio/webm';
  }

  function startRecording(stream) {
    // R√©activer AudioContext si suspendu (souvent n√©cessaire sur mobile/iOS)
    if (audioContext && audioContext.state === 'suspended') {
      audioContext.resume().catch(e => {
        warn('Impossible de r√©activer AudioContext:', e);
      });
    }

    const mimeType = getSupportedMimeType();
    let options = { mimeType };

    // Sur Firefox, certaines options peuvent causer des probl√®mes
    if (isFirefox()) {
      // Firefox peut avoir des probl√®mes avec certains codecs
      if (!MediaRecorder.isTypeSupported(mimeType)) {
        options = {}; // Laisser Firefox choisir
      }
    }

    try {
      mediaRecorder = new MediaRecorder(stream, options);
    } catch (e) {
      err('MediaRecorder non support√©:', mimeType, e);
      // Essayer sans options
      try {
        mediaRecorder = new MediaRecorder(stream);
      } catch (e2) {
        err('MediaRecorder √©chec complet:', e2);
        alert("Votre navigateur ne supporte pas l'enregistrement audio. Essayez un navigateur r√©cent (Chrome, Firefox, Edge, Safari).");
        toggleAnimation(false);
        // Stopper les streams en cas d'√©chec
        stopStreamTracks(currentMicStream);
        currentMicStream = null;
        stopStreamTracks(currentScreenStream);
        currentScreenStream = null;
        teardownAudioGraph();
        return;
      }
    }

    // R√©initialiser la d√©tection de silence pour le nouvel enregistrement
    silenceStopTriggered = false;
    silenceStartTime = null;
    silenceWarningShown = false;
    silenceAutoStopWarned = false;

    audioChunks = [];
    mediaRecorder.ondataavailable = (ev) => {
      if (ev.data && ev.data.size > 0) {
        audioChunks.push(ev.data);
        lastChunkTs = Date.now(); // [NEW] Watchdog timestamp
        saveChunkToBackup(ev.data); // [NEW] IndexedDB backup
      }
    };

    mediaRecorder.onerror = (event) => {
      err('MediaRecorder error:', event.error);
      const name = (event.error && event.error.name) || 'Unknown';
      const map = {
        NotSupportedError: "Format audio non support√© sur ce navigateur.",
        SecurityError: "Acc√®s refus√© pour des raisons de s√©curit√©.",
        InvalidStateError: "√âtat d'enregistrement invalide.",
        UnknownError: "Erreur inconnue lors de l'enregistrement."
      };
      alert(map[name] || "Erreur d'enregistrement : " + name);
      stopRecordingAndSubmitForm();
    };

    mediaRecorder.onstop = function () {
      // BUG FIX #3 : R√©initialiser le flag stopInProgress
      stopInProgress = false;

      setTimeout(() => {
        const finalMime = (mediaRecorder && mediaRecorder.mimeType) ? mediaRecorder.mimeType : mimeType;
        const audioBlob = new Blob(audioChunks, { type: finalMime });

        if (!audioBlob || audioBlob.size < MIN_BLOB_BYTES) {
          warn('Audio trop petit ou vide');
          audioChunks = [];
          alert("L'enregistrement est trop court ou vide. R√©essayez.");
          // BUG FIX Bonus : Cleanup m√™me en cas de return early
          stopStreamTracks(currentMicStream);
          currentMicStream = null;
          stopStreamTracks(currentScreenStream);
          currentScreenStream = null;
          teardownAudioGraph();
          return;
        }

        const ext = (finalMime.split(';')[0].split('/')[1] || 'webm');
        const now = new Date();
        const pad = n => n.toString().padStart(2, '0');
        const datePart = `${now.getFullYear()}-${pad(now.getMonth() + 1)}-${pad(now.getDate())}`;
        const timePart = `${pad(now.getHours())}h${pad(now.getMinutes())}`;
        const durSec = elapsedTimeInSeconds || Math.round(audioBlob.size / (128 * 1024));
        const dh = Math.floor(durSec / 3600), dm = Math.floor((durSec % 3600) / 60), ds = durSec % 60;
        const durationPart = `${pad(dh)}h${pad(dm)}m${pad(ds)}s`;
        const audioFileName = `Agilotext_${datePart}_${timePart}_${durationPart}.${ext}`;

        let hiddenName = form && form.querySelector('input[name="generatedFilename"]');
        if (form && !hiddenName) {
          hiddenName = document.createElement('input');
          hiddenName.type = 'hidden';
          hiddenName.name = 'generatedFilename';
          form.appendChild(hiddenName);
        }
        if (hiddenName) hiddenName.value = audioFileName;

        const fileInput = form && form.querySelector('input[type="file"]');
        // BUG FIX #1 : Utiliser const au lieu de let pour √©viter double d√©claration
        const pondInstance = window.FilePond && fileInput ? (() => {
          try { return FilePond.find(fileInput); } catch (e) { warn('FilePond.find:', e); return null; }
        })() : null;

        const doSubmit = () => {
          if (!form) return;
          if (typeof form.requestSubmit === 'function') form.requestSubmit();
          else if (submitButton) submitButton.click();
        };

        let submitted = false;
        let submitAttempts = 0;
        const SUBMIT_RETRY_DELAY = 150;
        const MAX_SUBMIT_WAIT_MS = 30000; // Plus s√ªr pour connexions lentes
        let submitTimeoutId = null;

        const submitWhenAdded = () => {
          if (submitted) return;

          // Option A : si FilePond existe, v√©rifier FilePond OU input natif (pas les deux)
          const ready =
            (pondInstance && pondInstance.getFiles && pondInstance.getFiles().length > 0 &&
              pondInstance.getFiles()[0].file && pondInstance.getFiles()[0].file.size > 0) ||
            (fileInput && fileInput.files && fileInput.files.length > 0 &&
              fileInput.files[0].size > 0);

          if (!ready) {
            submitAttempts++;
            if (submitAttempts * SUBMIT_RETRY_DELAY < MAX_SUBMIT_WAIT_MS) {
              submitTimeoutId = setTimeout(submitWhenAdded, SUBMIT_RETRY_DELAY);
            } else {
              warn('Fichier non pr√™t apr√®s 30s ‚Äî clic manuel possible.');
              // BUG FIX #2 : Cleanup listener avec try/catch pour √©viter memory leak
              try {
                if (!submitted && pondInstance && pondInstance.off) {
                  pondInstance.off('addfile', submitWhenAdded);
                }
              } catch (e) {
                warn('Cleanup listener FilePond:', e);
              }
            }
            return;
          }

          submitted = true;
          if (submitTimeoutId) clearTimeout(submitTimeoutId);
          // BUG FIX #2 : Cleanup listener avec try/catch
          try {
            if (pondInstance && pondInstance.off) {
              pondInstance.off('addfile', submitWhenAdded);
            }
          } catch (e) {
            warn('Cleanup listener FilePond:', e);
          }

          if (!navigator.onLine) {
            window.addEventListener('online', doSubmit, { once: true });
          } else {
            doSubmit();
          }
        };

        // Utiliser FilePond.addFile si disponible (plus robuste)
        const audioFile = new File([audioBlob], audioFileName, { type: finalMime });

        if (pondInstance && pondInstance.addFile) {
          // Option C : utiliser directement le then de addFile pour d√©clencher submitWhenAdded
          pondInstance.addFile(audioFile)
            .then(() => {
              // Le fichier est ajout√©, d√©clencher la soumission
              submitWhenAdded();
            })
            .catch((e) => {
              warn('Erreur FilePond.addFile, fallback sur simulateFileInput:', e);
              // Fallback : remplir aussi l'input natif
              if (fileInput) {
                simulateFileInput(fileInput, audioFile);
              }
              // Attendre un peu puis v√©rifier
              setTimeout(submitWhenAdded, 100);
            });
        } else {
          // Fallback : utiliser simulateFileInput
          if (fileInput) {
            simulateFileInput(fileInput, audioFile);
          }
          // Utiliser 'once' si disponible, sinon 'on' avec cleanup apr√®s timeout
          if (pondInstance && pondInstance.once) {
            pondInstance.once('addfile', submitWhenAdded);
          } else if (pondInstance && pondInstance.on) {
            pondInstance.on('addfile', submitWhenAdded);
            // BUG FIX #2 : Cleanup apr√®s MAX_SUBMIT_WAIT_MS avec try/catch
            setTimeout(() => {
              try {
                if (!submitted && pondInstance && pondInstance.off) {
                  pondInstance.off('addfile', submitWhenAdded);
                }
              } catch (e) {
                warn('Cleanup listener FilePond:', e);
              }
            }, MAX_SUBMIT_WAIT_MS + 1000);
          } else {
            // Pas de FilePond, v√©rifier directement
            setTimeout(submitWhenAdded, 100);
          }
        }

        setTimeout(() => {
          if (submitted) return;
          const items = pondInstance && pondInstance.getFiles ? pondInstance.getFiles() : [];
          if (items.length > 0 && items[0].file) submitWhenAdded();
          else if (!pondInstance) {
            setTimeout(() => {
              if (!navigator.onLine) window.addEventListener('online', doSubmit, { once: true });
              else doSubmit();
            }, 300);
          }
        }, 50);

        audioChunks = [];
        clearBackupSession(); // [NEW] Backup r√©ussie ‚Üí nettoyer IndexedDB
        setTimeout(() => downloadRecording(audioBlob, audioFileName), 1000);

        // BUG FIX #1 : Stopper les streams et fermer AudioContext APR√àS avoir construit le blob
        // (ne pas le faire dans stopRecordingAndSubmitForm pour √©viter blob vide)
        // Retirer le listener ended du screen stream si pr√©sent
        if (screenVideoTrack && onScreenEnded) {
          try {
            screenVideoTrack.removeEventListener('ended', onScreenEnded);
          } catch (e) {
            warn('Erreur retrait listener screen ended:', e);
          }
          screenVideoTrack = null;
          onScreenEnded = null;
        }
        stopStreamTracks(currentMicStream);
        currentMicStream = null;
        stopStreamTracks(currentScreenStream);
        currentScreenStream = null;
        teardownAudioGraph();
      }, 50);
    };

    // Timeslice pour flush r√©gulier (important pour Firefox)
    const timeslice = isFirefox() ? 1000 : 250;
    activeTimeslice = timeslice; // [NEW]
    try {
      mediaRecorder.start(timeslice);
    } catch (e) {
      try {
        mediaRecorder.start();
        activeTimeslice = 5000; // [NEW] Pas de timeslice ‚Üí estimation
      } catch (e2) {
        err('Impossible de d√©marrer MediaRecorder:', e2);
        alert('Erreur lors du d√©marrage de l\'enregistrement. Veuillez r√©essayer.');
        toggleAnimation(false);
        // Stopper les streams en cas d'√©chec
        stopStreamTracks(currentMicStream);
        currentMicStream = null;
        stopStreamTracks(currentScreenStream);
        currentScreenStream = null;
        teardownAudioGraph();
        return;
      }
    }

    toggleAnimation(true);
    if (startButton) startButton.disabled = true;
    if (stopButton) { stopButton.disabled = false; stopButton.style.display = 'flex'; }
    // Le test de pause sera fait au clic plut√¥t qu'au d√©marrage pour √©viter les artefacts
    if (pauseButton) {
      pauseButton.disabled = false;
      pauseButton.style.display = 'flex';
    }
    if (newButton) newButton.style.display = 'none';

    elapsedTimeInSeconds = 0;
    if (recordingTimeDisplay) recordingTimeDisplay.innerText = '00:00';
    recordingInterval = setInterval(updateRecordingTime, 1000);

    if (Number.isFinite(MAX_RECORDING_MS)) autoStopTimeout = setTimeout(stopRecordingAndSubmitForm, MAX_RECORDING_MS);
    else autoStopTimeout = null;

    // [NEW] D√©marrer les protections anti-perte
    startHeartbeat();
    startChunkWatchdog(activeTimeslice);
    requestWakeLock();
    startBackupSession();
    document.title = '‚è∫ ' + originalDocTitle; // [NEW] Titre onglet
  }

  if (pauseButton) {
    pauseButton.onclick = function () {
      if (!mediaRecorder) return;

      try {
        if (mediaRecorder.state === 'paused') {
          mediaRecorder.resume();
          if (pauseButtonText) pauseButtonText.innerText = 'Pause';
          // S√©curiser : clear avant de recr√©er pour √©viter les doublons
          clearInterval(recordingInterval);
          recordingInterval = setInterval(updateRecordingTime, 1000);
        } else if (mediaRecorder.state === 'recording') {
          mediaRecorder.pause();
          if (pauseButtonText) pauseButtonText.innerText = 'Reprendre';
          clearInterval(recordingInterval);
        }
        toggleAnimation(mediaRecorder.state !== 'paused');
      } catch (e) {
        warn('Erreur pause/resume:', e);
        alert('La pause n\'est pas support√©e sur ce navigateur.');
        // Cacher le bouton pause si non support√©
        if (pauseButton) pauseButton.style.display = 'none';
      }
    };
  }

  function stopRecordingAndSubmitForm() {
    // BUG FIX #3 : √âviter les doubles clics "Stop"
    if (stopInProgress) return;
    stopInProgress = true;

    // [NEW] Arr√™ter les protections anti-perte
    stopHeartbeat();
    stopChunkWatchdog();
    releaseWakeLock();
    document.title = originalDocTitle; // [NEW] Restaurer titre onglet

    // Arr√™ter le clignotement du titre
    stopTitleBlink();

    // Retirer le listener ended du screen stream si pr√©sent
    if (screenVideoTrack && onScreenEnded) {
      try {
        screenVideoTrack.removeEventListener('ended', onScreenEnded);
      } catch (e) {
        warn('Erreur retrait listener screen ended:', e);
      }
      screenVideoTrack = null;
      onScreenEnded = null;
    }

    // V√©rifier si on peut stopper le recorder (si oui, onstop se d√©clenchera et fera le cleanup)
    const canStopRecorder = mediaRecorder && mediaRecorder.state !== 'inactive';

    // S'assurer que toutes les donn√©es sont r√©cup√©r√©es avant d'arr√™ter
    // BUG FIX #2 : Aussi en paused
    try {
      if (mediaRecorder && (mediaRecorder.state === 'recording' || mediaRecorder.state === 'paused')) {
        mediaRecorder.requestData();
      }
    } catch (e) {
      warn('Erreur requestData dans stopRecordingAndSubmitForm:', e);
    }

    // Petit d√©lai pour laisser requestData finir avant de stopper
    const stopMediaRecorder = () => {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        try {
          mediaRecorder.stop();
        } catch (e) {
          warn('Erreur lors de l\'arr√™t du MediaRecorder:', e);
          // BUG FIX #2 : stop() a √©chou√© => onstop ne se d√©clenchera pas => d√©bloquer et cleanup
          stopInProgress = false;
          // Retirer le listener ended du screen stream si pr√©sent
          if (screenVideoTrack && onScreenEnded) {
            try {
              screenVideoTrack.removeEventListener('ended', onScreenEnded);
            } catch (e2) {
              warn('Erreur retrait listener screen ended:', e2);
            }
            screenVideoTrack = null;
            onScreenEnded = null;
          }
          // Cleanup imm√©diat pour √©viter les fuites
          stopStreamTracks(currentMicStream);
          currentMicStream = null;
          stopStreamTracks(currentScreenStream);
          currentScreenStream = null;
          teardownAudioGraph();
        }
      }
    };

    // Si on peut stopper le recorder, onstop se d√©clenchera et fera le cleanup
    if (canStopRecorder) {
      // Si on est d√©j√† en train d'arr√™ter (depuis checkSilence), on attend un peu
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        setTimeout(stopMediaRecorder, 150);
      } else {
        stopMediaRecorder();
      }
    } else {
      // BUG FIX #2 : Pas de onstop possible => cleanup imm√©diat
      // (mediaRecorder null ou d√©j√† inactive)
      // Retirer le listener ended du screen stream si pr√©sent
      if (screenVideoTrack && onScreenEnded) {
        try {
          screenVideoTrack.removeEventListener('ended', onScreenEnded);
        } catch (e) {
          warn('Erreur retrait listener screen ended:', e);
        }
        screenVideoTrack = null;
        onScreenEnded = null;
      }
      stopStreamTracks(currentMicStream);
      currentMicStream = null;
      stopStreamTracks(currentScreenStream);
      currentScreenStream = null;
      teardownAudioGraph();
    }

    clearInterval(recordingInterval);
    clearTimeout(autoStopTimeout);

    toggleAnimation(false);

    if (startButton) startButton.disabled = false;
    if (stopButton) { stopButton.disabled = true; stopButton.style.display = 'none'; }
    if (pauseButton) { pauseButton.disabled = true; pauseButton.style.display = 'none'; }
    if (newButton) newButton.style.display = 'flex';
    if (recordingDiv) recordingDiv.style.display = 'none';
    if (recordingTimeDisplay) recordingTimeDisplay.innerText = '00:00';

    warned5min = warned1min = false;
    isSharingScreen = false;

    // R√©initialiser la d√©tection de silence (mais PAS silenceStopTriggered ici)
    // silenceStopTriggered sera r√©initialis√© dans startRecording() pour le prochain enregistrement
    silenceStartTime = null;
    silenceWarningShown = false;
    silenceAutoStopWarned = false;
    // NOTE: silenceStopTriggered reste true jusqu'au prochain startRecording()
    // pour √©viter les red√©clenchements pendant les ~150ms avant mediaRecorder.stop()

    // BUG FIX #1 : Ne PAS stopper les streams ici si canStopRecorder (c'est fait dans onstop)
    // Les streams seront stopp√©s dans mediaRecorder.onstop apr√®s la construction du blob
    // OU imm√©diatement si canStopRecorder === false (d√©j√† fait plus haut)

    // Cacher le message d'erreur
    if (errorMessage) errorMessage.style.display = 'none';
  }

  if (stopButton) stopButton.onclick = stopRecordingAndSubmitForm;

  window.addEventListener('beforeunload', function (event) {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      try { mediaRecorder.requestData(); } catch (e) { }
      const msg = 'Enregistrement en cours. Voulez-vous vraiment quitter la page ?';
      event.returnValue = msg; return msg;
    }
  });

  window.addEventListener('unload', function () {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      try { mediaRecorder.requestData(); } catch (e) { }
      stopRecordingAndSubmitForm();
    }
  });

  window.addEventListener('pagehide', function () {
    if (mediaRecorder && mediaRecorder.state !== 'inactive') {
      try { mediaRecorder.requestData(); } catch (e) { }
      stopRecordingAndSubmitForm();
    }
  });

  // [ENHANCED] Gestion visibilit√© page + Wake Lock re-acquisition
  document.addEventListener('visibilitychange', function () {
    if (document.hidden && mediaRecorder && mediaRecorder.state === 'recording') {
      warn('Page en arri√®re-plan pendant l\'enregistrement');
    }
    // [NEW] R√©-acqu√©rir le Wake Lock quand la page redevient visible
    if (document.visibilityState === 'visible' && mediaRecorder && mediaRecorder.state !== 'inactive') {
      requestWakeLock();
    }
  });

  // [NEW] √âcouter freeze/resume pour d√©tecter les transitions OS
  if ('onfreeze' in document) {
    document.addEventListener('freeze', () => {
      warn('Page freeze d√©tect√©');
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        try { mediaRecorder.requestData(); } catch (e) { }
      }
    });
  }
  if ('onresume' in document) {
    document.addEventListener('resume', () => {
      log('Page resume d√©tect√©');
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        requestWakeLock();
        if (audioContext && audioContext.state === 'suspended') {
          audioContext.resume().catch(e => warn('Resume AudioContext failed:', e));
        }
      }
    });
  }


  // G√©rer le bouton "Recommencer" existant dans le HTML (#New-button_error)
  const newErrorButton = document.getElementById('New-button_error');
  if (newErrorButton) {
    newErrorButton.addEventListener('click', function () {
      // Cacher l'erreur et relancer l'enregistrement avec partage √©cran
      if (errorMessage) errorMessage.style.display = 'none';
      if (startSharingButton) {
        startSharingButton.click();
      } else {
        initiateRecording(true);
      }
    });
  }

  if (startButton) {
    startButton.addEventListener('click', function () {
      initiateRecording(false);
    });
  }

  try {
    navigator.mediaDevices?.addEventListener?.('devicechange', () => {
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        warn('devicechange d√©tect√© -> tentative de recovery micro');
        restartMic();
      }
    });
  } catch { }

  // [NEW] V√©rifier s'il y a un enregistrement √† r√©cup√©rer
  checkForRecovery();
});
